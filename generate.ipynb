{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import jupyter_black\n",
    "import IPython.display\n",
    "\n",
    "from GPT import *\n",
    "from utils.data import *\n",
    "from utils.utils import *\n",
    "from utils.metrics import *\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from loop_extraction.src.utils.utils import dataset_split\n",
    "from loop_extraction.src.utils.utils import folder_to_file\n",
    "from loop_extraction.src.utils.utils import folder_to_multiple_file\n",
    "\n",
    "from loop_extraction.src.utils.remi import *\n",
    "from loop_extraction.src.utils.constants import *\n",
    "from loop_extraction.src.utils.bpe_encode import MusicTokenizer\n",
    "\n",
    "jupyter_black.load(line_length=100)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load config\n",
    "with open(\"./config/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "#### set seed\n",
    "seed_everything(config[\"random_seed\"])\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "#### initialize model with GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(5 if use_cuda else \"cpu\")\n",
    "\n",
    "#### load tokenizer\n",
    "bpe_path = \"./loop_extraction/tokenizer/tokenizer_meta.json\"\n",
    "tokenizer = MusicTokenizer(bpe_path)\n",
    "\n",
    "bar_idx = tokenizer.encode([BAR_TOKEN])[0]\n",
    "pad_idx = tokenizer.encode([PAD_TOKEN])[0]\n",
    "eob_idx = tokenizer.encode([EOB_TOKEN])[0]\n",
    "\n",
    "vocab_size = tokenizer.bpe_vocab.get_vocab_size() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load datasets\n",
    "folder_path = \"/workspace/loop_generation_old/data/\"\n",
    "datasets = [\n",
    "    \"lmd_full_loop_\" + str(config[\"max_length\"]),\n",
    "    \"meta_midi_loop_\" + str(config[\"max_length\"]),\n",
    "]\n",
    "\n",
    "folder_list = []\n",
    "for dataset in datasets:\n",
    "    folder_list += glob.glob(os.path.join(folder_path, dataset, \"*\"))\n",
    "\n",
    "random.shuffle(folder_list)\n",
    "\n",
    "#### split song into train, val, test\n",
    "train_folder, val_folder, test_folder = dataset_split(folder_list, train_ratio=0.98, val_ratio=0.01)\n",
    "\n",
    "#### get file_path of each dataset\n",
    "test_files = folder_to_multiple_file(test_folder, k=3)\n",
    "print(f\"test_files : {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load model skeleton\n",
    "model = GPT(\n",
    "    vocab_size,\n",
    "    pad_idx,\n",
    "    dim_model=config[\"dim_model\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    num_heads=config[\"num_heads\"],\n",
    "    multiplier=config[\"multiplier\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    max_length=config[\"max_length\"],\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"The number of parameters : {sizeof_number(total_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load pre-trained model\n",
    "folder_path = \"/workspace/loop_generation_old/model\"\n",
    "model_path = \"version_GPT-medium-random_drop_0.5-max_length_1024-epoch=4-val_loss=0.4794.ckpt\"\n",
    "\n",
    "model = model.load_from_checkpoint(\n",
    "    os.path.join(folder_path, model_path),\n",
    "    vocab_size=vocab_size,\n",
    "    pad_idx=pad_idx,\n",
    "    dim_model=config[\"dim_model\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    num_heads=config[\"num_heads\"],\n",
    "    multiplier=config[\"multiplier\"],\n",
    "    dropout=config[\"dropout\"],\n",
    "    max_length=config[\"max_length\"],\n",
    "    map_location=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tails(loop, end_time, fs):\n",
    "    play_time = int(fs * end_time)\n",
    "\n",
    "    loop_fs = loop.fluidsynth(fs=fs)\n",
    "    diff = loop_fs.shape[0] - play_time\n",
    "\n",
    "    rand = random.uniform(0, 0.2)\n",
    "    margin = int(diff * rand) if diff > 0 else 0\n",
    "\n",
    "    return loop_fs[: play_time + margin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100.0\n",
    "\n",
    "gen_path = os.path.join(\"./evaluation\", \"gen_sample_cond_full\")\n",
    "true_path = os.path.join(\"./evaluation\", \"extension1\")\n",
    "\n",
    "tokenizer.add_tokens([START_TOKEN])\n",
    "start_token = tokenizer.encode_meta(START_TOKEN)\n",
    "\n",
    "for i, file_path in enumerate(test_files):\n",
    "    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "\n",
    "    ### generate conditions\n",
    "    cond = convert_cond(x, tokenizer, random_drop=0)\n",
    "    cond = start_token + cond + [bar_idx]\n",
    "    cond = torch.tensor(cond, dtype=torch.long)\n",
    "\n",
    "    # ###convert inst\n",
    "    # cond = sorted(tokenizer.encode(x[\"inst\"]))\n",
    "    # cond = start_token + cond + [bar_idx]\n",
    "    # cond = torch.tensor(cond, dtype=torch.long)\n",
    "\n",
    "    ## generate samples\n",
    "    gen_loop = generate(\n",
    "        cond,\n",
    "        model,\n",
    "        device,\n",
    "        [bar_idx, eob_idx],\n",
    "        temp=1,\n",
    "        top_k=10,\n",
    "        sample=True,\n",
    "        max_length=config[\"max_length\"],\n",
    "    )\n",
    "\n",
    "    ori_loop_remi, ori_end_time = remi2midi(x[\"loop\"] + x[\"loop\"])\n",
    "    gen_loop_remi, gen_end_time = remi2midi(gen_loop)\n",
    "\n",
    "    ori_loop_fs = trim_tails(ori_loop_remi, ori_end_time, fs)\n",
    "    gen_loop_fs = trim_tails(gen_loop_remi, gen_end_time, fs)\n",
    "\n",
    "    ori_file_path = os.path.join(true_path, \"true_loop_\" + file_name) + \".mid\"\n",
    "    gen_file_path = os.path.join(gen_path, \"gen_cond_full_\" + file_name) + \".mid\"\n",
    "\n",
    "    print(\"go\")\n",
    "    break\n",
    "    # write(ori_file_path, int(fs), ori_loop_fs.astype(np.float32))\n",
    "    # write(gen_file_path, int(fs), gen_loop_fs.astype(np.float32))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"We are processing the {i}th file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 44100.0\n",
    "\n",
    "ori_loop_remi, ori_end_time = remi2midi(x[\"loop\"])\n",
    "gen_loop_remi, gen_end_time = remi2midi(gen_loop)\n",
    "\n",
    "ori_loop_fs = trim_tails(ori_loop_remi, ori_end_time, fs)\n",
    "gen_loop_fs = trim_tails(gen_loop_remi, gen_end_time, fs)\n",
    "\n",
    "IPython.display.display(IPython.display.Audio(ori_loop_fs, rate=rate))\n",
    "IPython.display.display(IPython.display.Audio(gen_loop_fs, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
