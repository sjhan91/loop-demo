{
    "version": "GPT-medium",
    "random_seed": 0,
    "batch_size": 4,
    "num_workers": 16,
    "dim_model": 1024,
    "num_layers": 24,
    "num_heads": 16,
    "multiplier": 2.667,
    "lr": 8e-4,
    "dropout": 0.1,
    "random_drop": 0.5,
    "weight_decay": 0.1,
    "max_length": 1024,
    "warm_up": 2000,
    "epochs": 20,
    "acc_batch": 8,
    "gpus": [4, 5, 6, 7]
}